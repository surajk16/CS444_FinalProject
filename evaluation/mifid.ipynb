{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip, pickle\n",
    "import tensorflow as tf\n",
    "from scipy import linalg\n",
    "import pathlib\n",
    "import urllib\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "class KernelEvalException(Exception):\n",
    "    pass\n",
    "\n",
    "model_params = {\n",
    "    'Inception': {\n",
    "        'name': 'Inception', \n",
    "        'imsize': 64,\n",
    "        'output_layer': 'Pretrained_Net/pool_3:0', \n",
    "        'input_layer': 'Pretrained_Net/ExpandDims:0',\n",
    "        'output_shape': 2048,\n",
    "        'cosine_distance_eps': 0.1\n",
    "        }\n",
    "}\n",
    "\n",
    "def create_model_graph(pth):\n",
    "    \"\"\"Creates a graph from saved GraphDef file.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf.io.gfile.GFile( pth, 'rb') as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString( f.read())\n",
    "        _ = tf.import_graph_def( graph_def, name='Pretrained_Net')\n",
    "\n",
    "def _get_model_layer(sess, model_name):\n",
    "    # layername = 'Pretrained_Net/final_layer/Mean:0'\n",
    "    layername = model_params[model_name]['output_layer']\n",
    "    layer = sess.graph.get_tensor_by_name(layername)\n",
    "    ops = layer.graph.get_operations()\n",
    "    for op_idx, op in enumerate(ops):\n",
    "        for o in op.outputs:\n",
    "            shape = o.get_shape()\n",
    "            if shape._dims != []:\n",
    "              shape = [s.value for s in shape]\n",
    "              new_shape = []\n",
    "              for j, s in enumerate(shape):\n",
    "                if s == 1 and j == 0:\n",
    "                  new_shape.append(None)\n",
    "                else:\n",
    "                  new_shape.append(s)\n",
    "              o.__dict__['_shape_val'] = tf.TensorShape(new_shape)\n",
    "    return layer\n",
    "\n",
    "def get_activations(images, sess, model_name, batch_size=50, verbose=False):\n",
    "    \"\"\"Calculates the activations of the pool_3 layer for all images.\n",
    "\n",
    "    Params:\n",
    "    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n",
    "                     must lie between 0 and 256.\n",
    "    -- sess        : current session\n",
    "    -- batch_size  : the images numpy array is split into batches with batch size\n",
    "                     batch_size. A reasonable batch size depends on the disposable hardware.\n",
    "    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n",
    "                     batches is reported.\n",
    "    Returns:\n",
    "    -- A numpy array of dimension (num images, 2048) that contains the\n",
    "       activations of the given tensor when feeding inception with the query tensor.\n",
    "    \"\"\"\n",
    "    inception_layer = _get_model_layer(sess, model_name)\n",
    "    n_images = images.shape[0]\n",
    "    if batch_size > n_images:\n",
    "        print(\"warning: batch size is bigger than the data size. setting batch size to data size\")\n",
    "        batch_size = n_images\n",
    "    n_batches = n_images//batch_size + 1\n",
    "    pred_arr = np.empty((n_images,model_params[model_name]['output_shape']))\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        if verbose:\n",
    "            print(\"\\rPropagating batch %d/%d\" % (i+1, n_batches), end=\"\", flush=True)\n",
    "        start = i*batch_size\n",
    "        if start+batch_size < n_images:\n",
    "            end = start+batch_size\n",
    "        else:\n",
    "            end = n_images\n",
    "                    \n",
    "        batch = images[start:end]\n",
    "        pred = sess.run(inception_layer, {model_params[model_name]['input_layer']: batch})\n",
    "        pred_arr[start:end] = pred.reshape(-1,model_params[model_name]['output_shape'])\n",
    "    if verbose:\n",
    "        print(\" done\")\n",
    "    return pred_arr\n",
    "\n",
    "\n",
    "# def calculate_memorization_distance(features1, features2):\n",
    "#     neigh = NearestNeighbors(n_neighbors=1, algorithm='kd_tree', metric='euclidean')\n",
    "#     neigh.fit(features2) \n",
    "#     d, _ = neigh.kneighbors(features1, return_distance=True)\n",
    "#     print('d.shape=',d.shape)\n",
    "#     return np.mean(d)\n",
    "\n",
    "def normalize_rows(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    function that normalizes each row of the matrix x to have unit length.\n",
    "\n",
    "    Args:\n",
    "     ``x``: A numpy matrix of shape (n, m)\n",
    "\n",
    "    Returns:\n",
    "     ``x``: The normalized (by row) numpy matrix.\n",
    "    \"\"\"\n",
    "    return np.nan_to_num(x/np.linalg.norm(x, ord=2, axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def cosine_distance(features1, features2):\n",
    "    features1_nozero = features1[np.sum(features1, axis=1) != 0]\n",
    "    features2_nozero = features2[np.sum(features2, axis=1) != 0]\n",
    "    norm_f1 = normalize_rows(features1_nozero)\n",
    "    norm_f2 = normalize_rows(features2_nozero)\n",
    "\n",
    "    d = 1.0-np.abs(np.matmul(norm_f1, norm_f2.T))\n",
    "    print('d.shape=',d.shape)\n",
    "    print('np.min(d, axis=1).shape=',np.min(d, axis=1).shape)\n",
    "    mean_min_d = np.mean(np.min(d, axis=1))\n",
    "    print('distance=',mean_min_d)\n",
    "    return mean_min_d\n",
    "\n",
    "\n",
    "def distance_thresholding(d, eps):\n",
    "    if d < eps:\n",
    "        return d\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "            \n",
    "    Stable version by Dougal J. Sutherland.\n",
    "\n",
    "    Params:\n",
    "    -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n",
    "             inception net ( like returned by the function 'get_predictions')\n",
    "             for generated samples.\n",
    "    -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n",
    "               on an representive data set.\n",
    "    -- sigma1: The covariance matrix over activations of the pool_3 layer for\n",
    "               generated samples.\n",
    "    -- sigma2: The covariance matrix over activations of the pool_3 layer,\n",
    "               precalcualted on an representive data set.\n",
    "\n",
    "    Returns:\n",
    "    --   : The Frechet Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n",
    "    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n",
    "        warnings.warn(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "    \n",
    "    # numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError(\"Imaginary component {}\".format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    print('covmean.shape=',covmean.shape)\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "\n",
    "def calculate_activation_statistics(images, sess, model_name, batch_size=50, verbose=False):\n",
    "    \"\"\"Calculation of the statistics used by the FID.\n",
    "    Params:\n",
    "    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n",
    "                     must lie between 0 and 255.\n",
    "    -- sess        : current session\n",
    "    -- batch_size  : the images numpy array is split into batches with batch size\n",
    "                     batch_size. A reasonable batch size depends on the available hardware.\n",
    "    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n",
    "                     batches is reported.\n",
    "    Returns:\n",
    "    -- mu    : The mean over samples of the activations of the pool_3 layer of\n",
    "               the incption model.\n",
    "    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n",
    "               the incption model.\n",
    "    \"\"\"\n",
    "    act = get_activations(images, sess, model_name, batch_size, verbose)\n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma, act\n",
    "    \n",
    "def _handle_path_memorization(path, sess, model_name, is_checksize, is_check_png):\n",
    "    path = pathlib.Path(path)\n",
    "    files = list(path.glob('*/*.jpg')) + list(path.glob('*/*.png'))\n",
    "    imsize = model_params[model_name]['imsize']\n",
    "\n",
    "    # In production we don't resize input images. This is just for demo purpose.\n",
    "    # x = np.array([np.array(img_read_checks(fn, imsize, is_checksize, imsize, is_check_png)) for fn in files])\n",
    "    \n",
    "    x = np.empty([len(files), 64, 64, 3])\n",
    "    for i, fn in enumerate(files):\n",
    "        x[i, :, :, :] = np.array(img_read_checks(fn, imsize, is_checksize, imsize, is_check_png))\n",
    "        break\n",
    "    \n",
    "    m, s, features = calculate_activation_statistics(x, sess, model_name)\n",
    "    del x #clean up memory\n",
    "    return m, s, features\n",
    "\n",
    "# check for image size\n",
    "def img_read_checks(filename, resize_to, is_checksize=False, check_imsize = 64, is_check_png = False):\n",
    "    im = Image.open(str(filename))\n",
    "    if is_checksize and im.size != (check_imsize,check_imsize):\n",
    "        raise KernelEvalException('The images are not of size '+str(check_imsize))\n",
    "    \n",
    "    if is_check_png and im.format != 'PNG':\n",
    "        raise KernelEvalException('Only PNG images should be submitted.')\n",
    "\n",
    "    if resize_to is None:\n",
    "        return im\n",
    "    else:\n",
    "        print(np.array(im.resize((resize_to,resize_to),Image.ANTIALIAS)).shape)\n",
    "        return im.resize((resize_to,resize_to),Image.ANTIALIAS)\n",
    "\n",
    "def calculate_kid_given_paths(paths, model_name, model_path, feature_path=None):\n",
    "    ''' Calculates the KID of two paths. '''\n",
    "    # tf.reset_default_graph()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    create_model_graph(str(model_path))\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        ops = sess.graph.get_operations()\n",
    "        for op in ops:\n",
    "            if \"pool\" in op.name:\n",
    "                print(op.name,op.values())\n",
    "        m1, s1, features1 = _handle_path_memorization(paths[0], sess, model_name, is_checksize = False, is_check_png = False)\n",
    "        if feature_path is None:\n",
    "            m2, s2, features2 = _handle_path_memorization(paths[1], sess, model_name, is_checksize = False, is_check_png = False)\n",
    "        else:\n",
    "            with np.load(feature_path) as f:\n",
    "                m2, s2, features2 = f['m'], f['s'], f['features']\n",
    "\n",
    "        print('m1,m2 shape=',(m1.shape,m2.shape),'s1,s2=',(s1.shape,s2.shape))\n",
    "        print('starting calculating FID')\n",
    "        fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n",
    "        print('done with FID, starting distance calculation')\n",
    "        distance = cosine_distance(features1, features2)        \n",
    "        return fid_value, distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool/CheckNumerics (<tf.Tensor 'pool/CheckNumerics:0' shape=(1, 147, 147, 64) dtype=float32>,)\n",
      "pool/control_dependency (<tf.Tensor 'pool/control_dependency:0' shape=(1, 147, 147, 64) dtype=float32>,)\n",
      "pool (<tf.Tensor 'pool:0' shape=(1, 73, 73, 64) dtype=float32>,)\n",
      "pool_1/CheckNumerics (<tf.Tensor 'pool_1/CheckNumerics:0' shape=(1, 71, 71, 192) dtype=float32>,)\n",
      "pool_1/control_dependency (<tf.Tensor 'pool_1/control_dependency:0' shape=(1, 71, 71, 192) dtype=float32>,)\n",
      "pool_1 (<tf.Tensor 'pool_1:0' shape=(1, 35, 35, 192) dtype=float32>,)\n",
      "mixed/tower_2/pool (<tf.Tensor 'mixed/tower_2/pool:0' shape=(1, 35, 35, 192) dtype=float32>,)\n",
      "mixed_1/tower_2/pool (<tf.Tensor 'mixed_1/tower_2/pool:0' shape=(1, 35, 35, 256) dtype=float32>,)\n",
      "mixed_2/tower_2/pool (<tf.Tensor 'mixed_2/tower_2/pool:0' shape=(1, 35, 35, 288) dtype=float32>,)\n",
      "mixed_3/pool/CheckNumerics (<tf.Tensor 'mixed_3/pool/CheckNumerics:0' shape=(1, 35, 35, 288) dtype=float32>,)\n",
      "mixed_3/pool/control_dependency (<tf.Tensor 'mixed_3/pool/control_dependency:0' shape=(1, 35, 35, 288) dtype=float32>,)\n",
      "mixed_3/pool (<tf.Tensor 'mixed_3/pool:0' shape=(1, 17, 17, 288) dtype=float32>,)\n",
      "mixed_4/tower_2/pool (<tf.Tensor 'mixed_4/tower_2/pool:0' shape=(1, 17, 17, 768) dtype=float32>,)\n",
      "mixed_5/tower_2/pool (<tf.Tensor 'mixed_5/tower_2/pool:0' shape=(1, 17, 17, 768) dtype=float32>,)\n",
      "mixed_6/tower_2/pool (<tf.Tensor 'mixed_6/tower_2/pool:0' shape=(1, 17, 17, 768) dtype=float32>,)\n",
      "mixed_7/tower_2/pool (<tf.Tensor 'mixed_7/tower_2/pool:0' shape=(1, 17, 17, 768) dtype=float32>,)\n",
      "mixed_8/pool/CheckNumerics (<tf.Tensor 'mixed_8/pool/CheckNumerics:0' shape=(1, 17, 17, 768) dtype=float32>,)\n",
      "mixed_8/pool/control_dependency (<tf.Tensor 'mixed_8/pool/control_dependency:0' shape=(1, 17, 17, 768) dtype=float32>,)\n",
      "mixed_8/pool (<tf.Tensor 'mixed_8/pool:0' shape=(1, 8, 8, 768) dtype=float32>,)\n",
      "mixed_9/tower_2/pool (<tf.Tensor 'mixed_9/tower_2/pool:0' shape=(1, 8, 8, 1280) dtype=float32>,)\n",
      "mixed_10/tower_2/pool/CheckNumerics (<tf.Tensor 'mixed_10/tower_2/pool/CheckNumerics:0' shape=(1, 8, 8, 2048) dtype=float32>,)\n",
      "mixed_10/tower_2/pool/control_dependency (<tf.Tensor 'mixed_10/tower_2/pool/control_dependency:0' shape=(1, 8, 8, 2048) dtype=float32>,)\n",
      "mixed_10/tower_2/pool (<tf.Tensor 'mixed_10/tower_2/pool:0' shape=(1, 8, 8, 2048) dtype=float32>,)\n",
      "pool_3 (<tf.Tensor 'pool_3:0' shape=(1, 1, 1, 2048) dtype=float32>,)\n",
      "pool_3/_reshape/shape (<tf.Tensor 'pool_3/_reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "pool_3/_reshape (<tf.Tensor 'pool_3/_reshape:0' shape=(1, 2048) dtype=float32>,)\n",
      "(64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/condor/execute/dir_97164/ipykernel_38393/774113266.py:237: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  print(np.array(im.resize((resize_to,resize_to),Image.ANTIALIAS)).shape)\n",
      "/srv/condor/execute/dir_97164/ipykernel_38393/774113266.py:238: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  return im.resize((resize_to,resize_to),Image.ANTIALIAS)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'Pretrained_Net/pool_3:0' refers to a Tensor which does not exist. The operation, 'Pretrained_Net/pool_3', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m public_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./classify_image_graph_def.pb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m fid_epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10e-15\u001b[39m\n\u001b[0;32m----> 9\u001b[0m fid_value_public, distance_public \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_kid_given_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInception\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpublic_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m distance_public \u001b[38;5;241m=\u001b[39m distance_thresholding(distance_public, model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInception\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine_distance_eps\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFID_public: \u001b[39m\u001b[38;5;124m\"\u001b[39m, fid_value_public, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance_public: \u001b[39m\u001b[38;5;124m\"\u001b[39m, distance_public, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiplied_public: \u001b[39m\u001b[38;5;124m\"\u001b[39m, fid_value_public \u001b[38;5;241m/\u001b[39m(distance_public \u001b[38;5;241m+\u001b[39m fid_epsilon))\n",
      "Cell \u001b[0;32mIn[45], line 251\u001b[0m, in \u001b[0;36mcalculate_kid_given_paths\u001b[0;34m(paths, model_name, model_path, feature_path)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28mprint\u001b[39m(op\u001b[38;5;241m.\u001b[39mname,op\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m--> 251\u001b[0m m1, s1, features1 \u001b[38;5;241m=\u001b[39m \u001b[43m_handle_path_memorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_checksize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_check_png\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     m2, s2, features2 \u001b[38;5;241m=\u001b[39m _handle_path_memorization(paths[\u001b[38;5;241m1\u001b[39m], sess, model_name, is_checksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, is_check_png \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[45], line 221\u001b[0m, in \u001b[0;36m_handle_path_memorization\u001b[0;34m(path, sess, model_name, is_checksize, is_check_png)\u001b[0m\n\u001b[1;32m    218\u001b[0m     x[i, :, :, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_read_checks(fn, imsize, is_checksize, imsize, is_check_png))\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m m, s, features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_activation_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x \u001b[38;5;66;03m#clean up memory\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m, s, features\n",
      "Cell \u001b[0;32mIn[45], line 203\u001b[0m, in \u001b[0;36mcalculate_activation_statistics\u001b[0;34m(images, sess, model_name, batch_size, verbose)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_activation_statistics\u001b[39m(images, sess, model_name, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculation of the statistics used by the FID.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    Params:\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m               the incption model.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     act \u001b[38;5;241m=\u001b[39m \u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     mu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(act, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    205\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(act, rowvar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[45], line 69\u001b[0m, in \u001b[0;36mget_activations\u001b[0;34m(images, sess, model_name, batch_size, verbose)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_activations\u001b[39m(images, sess, model_name, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the activations of the pool_3 layer for all images.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    Params:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m       activations of the given tensor when feeding inception with the query tensor.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     inception_layer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     n_images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m>\u001b[39m n_images:\n",
      "Cell \u001b[0;32mIn[45], line 38\u001b[0m, in \u001b[0;36m_get_model_layer\u001b[0;34m(sess, model_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_layer\u001b[39m(sess, model_name):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# layername = 'Pretrained_Net/final_layer/Mean:0'\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     layername \u001b[38;5;241m=\u001b[39m model_params[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_layer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayername\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     ops \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mget_operations()\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op_idx, op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ops):\n",
      "File \u001b[0;32m~/miniconda3/envs/oneshotCLIP/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4188\u001b[0m, in \u001b[0;36mGraph.get_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   4186\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor names are strings (or similar), not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   4187\u001b[0m                   \u001b[38;5;28mtype\u001b[39m(name)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 4188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_graph_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/oneshotCLIP/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4012\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4009\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001b[1;32m   4011\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 4012\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_graph_element_locked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/oneshotCLIP/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4052\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4050\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_name[op_name]\n\u001b[1;32m   4051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4052\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m refers to a Tensor which does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4053\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist. The operation, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, does not exist in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4054\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(name), \u001b[38;5;28mrepr\u001b[39m(op_name)))\n\u001b[1;32m   4055\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   4056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39moutputs[out_n]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'Pretrained_Net/pool_3:0' refers to a Tensor which does not exist. The operation, 'Pretrained_Net/pool_3', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "generated_images_path = '../data/all-dogs'\n",
    "real_images_path = '../data/all-dogs'\n",
    "images_path = [generated_images_path, real_images_path]\n",
    "\n",
    "public_path = './classify_image_graph_def.pb'\n",
    "\n",
    "fid_epsilon = 10e-15\n",
    "\n",
    "fid_value_public, distance_public = calculate_kid_given_paths(images_path, 'Inception', public_path)\n",
    "distance_public = distance_thresholding(distance_public, model_params['Inception']['cosine_distance_eps'])\n",
    "print(\"FID_public: \", fid_value_public, \"distance_public: \", distance_public, \"multiplied_public: \", fid_value_public /(distance_public + fid_epsilon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
